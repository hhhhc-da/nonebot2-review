# å†…å®¹å®¡æŸ¥æœºå™¨äºº

ä½¿ç”¨ `nonebot` çš„ `å†…å®¹å®¡æŸ¥ bot`, åŸºäº `Bert` å’Œ `Llama`

![image](./images/test.png)

### éƒ¨ç½²æ–¹æ³• (éœ€è¦ä¸€äº›å‰ç½®çŸ¥è¯†)

ä¸‹è½½ `bert-base-chinese` çš„æ—¶å€™å»ºè®®ç”¨é•œåƒç«™

```bash
git clone https://hf-mirror.com/google-bert/bert-base-chinese
```

åœ¨æ­¤ä¹‹å‰ä½ éœ€è¦å…ˆå®‰è£…å¥½ `requirements.txt` å†…çš„æ‰€æœ‰å†…å®¹åˆ°ä½ çš„ `python` ç¯å¢ƒå†…

```bash
# Windows ä¸‹ä½¿ç”¨æ¿€æ´»ç¯å¢ƒ
.venv\Scripts\activate.bat

pip install -r requirements.txt
```

éœ€è¦ç¼–è¯‘å¾ˆä¹…, ä¸»è¦æ˜¯ `llama-cpp-python` è¦è‡ªå·±ç¼–è¯‘è€Œä¸” `llama` ä¹Ÿä¸å°

éœ€è¦è‡ªå·±æ‰“åŒ…æˆæ–‡ä»¶å¤¹ `nonebot_plugin_{è¿™é‡Œå¡«ä½ è¦èµ·çš„åå­—}` ç„¶åæ”¾è¿› `plugin` æ–‡ä»¶å¤¹å°±å¯ä»¥äº†

`nb create` ä¹‹åä¼šè‡ªåŠ¨å¸®ä½ åˆ›å»º `plugin` æ–‡ä»¶å¤¹çš„

ä¹‹åç›´æ¥ `cmd` æ­£å¸¸å¯åŠ¨å°±å¯ä»¥äº†

```bash
# å¦‚æœä½ ä¸å¯¹æºç è¿›è¡Œä¿®æ”¹ä¹Ÿå¯ä»¥ä¸ reload
nb run --reload
```

---

### Bert + Deepseek åˆ†ç±»å™¨ä»‹ç»

å¦‚ä½ æ‰€è§, è¿™é‡Œé›†æˆäº† `Bert` å’Œ `Deepseek` çš„åç«¯, åªæ˜¯ `Deepseek` çš„åç«¯è¿è¡Œçš„æ•ˆæœå¾ˆç³Ÿç³•

å°±åƒè¿™æ ·ğŸ‘‡

```
0	æ˜¯
0	å¦, å†…å®¹æ²¡æœ‰è¿è§„ã€‚
0	å¦
0	æ˜¯, è¿™æ®µæ–‡æœ¬è¿è§„å†…å®¹æ˜¯â€œæˆ‘ç©¿æ¯›è¡£å°±æ˜¯å¾ˆéš¾å—é‡Œé¢å¿…é¡»è¦ç©¿ä¸ªæ‰“åº•è¡«â€ã€‚
0	å¦ã€‚è¿™æ®µæ–‡æœ¬æ²¡æœ‰åŒ…å«ä»»ä½•é•¿å¹¿å‘Š, å› æ­¤ä¸è¿è§„ã€‚
0	æ˜¯, å†…å®¹ä¸­åŒ…å«é•¿å¹¿å‘Š, å¯èƒ½å½±å“ç¾¤èŠæ°›å›´ã€‚
0	å¦
0	æ˜¯
0	æ˜¯ã€‚è¿è§„å†…å®¹æ˜¯â€œå¯è®¡ç®—æ•°â€ã€‚
0	å¦ã€‚è¿™æ®µæ–‡æœ¬æ²¡æœ‰æ¶‰åŠä»»ä½•é•¿å¹¿å‘Š, å†…å®¹æ˜¯æ­£å¸¸çš„è‡ªæˆ‘ä»‹ç»ã€‚
0	æ˜¯ã€‚è¿™æ®µæ–‡æœ¬åŒ…å«äº†é•¿å¹¿å‘Š"åˆçœ‹ä¸€é›†", è¿™å±äºå½±å“ç¾¤èŠæ°›å›´çš„å†…å®¹ã€‚
0	æ˜¯, è¿è§„å†…å®¹æ˜¯ä¸å‘å¹¿å‘Šä¸åˆ·å±ã€‚
0	æ˜¯, è¿è§„å†…å®¹æ˜¯è¿™æ¡é•¿å¹¿å‘Šå¯¼è‡´çš„è´Ÿé¢æƒ…ç»ªå’Œç”¨æˆ·æ€€ç–‘å¹¿å‘Šè™šå‡ã€‚
0	å¦
0	å¦ã€‚è¿™æ®µå†…å®¹æ²¡æœ‰æ¶‰åŠä»»ä½•é•¿å¹¿å‘Šæˆ–è¿è§„å†…å®¹ã€‚
0	æ˜¯, è¿è§„å†…å®¹æ˜¯â€œé˜Ÿå‹æ¥è¿‘ç‡æ›´é«˜â€ã€‚
0	æ˜¯, è¿è§„å†…å®¹æ˜¯â€œæ–—ä¸å»æŠŠæ”»è§’é™åˆ¶å…³äº†å—â€ã€‚
```

å·¦è¾¹æ˜¯åŸæ•°æ®çš„çœŸå®æƒ…å†µ, è€Œå³è¾¹æ˜¯ `Deepseek` èƒ¡è¯Œçš„, è¿™å°±æ˜¯æˆ‘ä¸ºå•¥ä¸ç”¨ `Deepseek-r1` åšåˆ†ç±»äº†

**å…¶å®ä¸»è¦æ˜¯ Bert è®­ç»ƒæ•ˆæœä¹Ÿä¸å·®**, é¿å…å‡ºç°äº†è¯¯åˆ¤çš„é—®é¢˜, ç”±äºæ•°æ®é›†æœ‰è¾ƒå¤§çš„å€¾æ–œ

æ‰€ä»¥è®­ç»ƒæŠ¥å‘Šé•¿ä¸‹é¢è¿™æ ·, æœ‰é—®é¢˜çš„ç²¾ç¡®åº¦é«˜è€Œå¬å›ç‡ä½, æ²¡é—®é¢˜çš„ç²¾ç¡®ç‡ç¨ä½ä½†å¬å›ç‡é«˜

p.s. å¦‚æœé•¿æœŸæ‰“æ‰°åˆ°ä¹Ÿæ˜¯ä¸å¤ªå¥½çš„è¡Œä¸º...

```
æ··æ·†çŸ©é˜µ:
[[23  0]
 [ 2  1]]

åˆ†ç±»æŠ¥å‘Š:
              precision    recall  f1-score   support

           0       0.92      1.00      0.96        23
           1       1.00      0.33      0.50         3

    accuracy                           0.92        26
   macro avg       0.96      0.67      0.73        26
weighted avg       0.93      0.92      0.91        26
```

---

### å…·ä½“åˆ¤æ–­é€»è¾‘

æ‰€æœ‰å·¥å…·æœ€åéƒ½å°è£…åˆ° `review.py` å†…äº†

å¯ä»¥ç›´æ¥ä½¿ç”¨ä¸€ä¸ªå‡½æ•°è§£å†³è¿™äº›é—®é¢˜ğŸ‘‡

```python
class Review():

    # æ­¤å¤„çœç•¥ä¸€å¤§å †å­—

    def func(self, text: list):
        '''
        æˆ‘ä»¬æ ¹æ®å¥å­é•¿åº¦å†³å®šæ˜¯å¦ä½¿ç”¨ LLM å»åˆ¤æ–­
        è¾ƒé•¿çš„å¥å­ä¸€èˆ¬ä¹Ÿä¸ä¼šå¤ªé¢‘ç¹çš„è¯·æ±‚, æ‰€ä»¥æ€ä¹ˆå¤„ç†å½’æœ€ç»ˆéƒ¨ç½²ç®¡ç†å³å¯
        ä¸ºäº†é˜²æ­¢é€†å¤©ä½¿ç”¨è¶…é•¿æ¨¡å‹è¿˜æ˜¯åŠ äº†åˆ¤æ–­
        '''
        ret = None
        if len(text) > self._length:
            print("ä½¿ç”¨ Deepseek + Bert åˆ¤æ–­")
            ret = self.deepseek_predict(text=text, max_len=512)
        else:
            print("ä½¿ç”¨ Bert è¿›è¡Œåˆ¤æ–­")
            # min ä¸€ä¸‹, è°çŸ¥é“æœ‰æ²¡æœ‰äººç”¨é€†å¤©æ¨¡å‹
            ret = self.bert_predict(text=text, max_len=min(512, self._length))
        return ret
```

æœ‰ä¸€äº› `Python` åŸºç¡€çš„ç”¨æˆ·ä¸éš¾çœ‹å‡ºè¿™ä¸€æ®µä»£ç åœ¨æ–‡æœ¬é•¿åº¦ä¸åŒæ—¶æœ‰ä¸åŒçš„ç­–ç•¥

|æ–¹æ¡ˆ|ä¼˜ç‚¹|ç¼ºç‚¹|
|----|----|----|
|Bert|è¿ç®—é€Ÿåº¦å¿«ã€éçº¿æ€§åˆ†å‰²æ•ˆæœå¥½|ç°å®æƒ…å†µå¤ªå¤æ‚, ä¸èƒ½ä¿è¯ä¸€å®šå¯åˆ†|
|Deepseek + Bert|æ¨¡å‹å®¹é‡å¤§, Hidden çŠ¶æ€è¿œè¶… Bert|ä¸ç¨³å®š, è€Œä¸”è¿™ä¸ªå‚æ•°å¤ªå°|

åæ­£å°±æ˜¯ä¸åŒçš„æ–¹æ¡ˆæœ‰ä¸åŒçš„ç‰¹ç‚¹, æ²¡æœ‰è¯´ç¡®å®šå“ªä¸€ä¸ªå°±æ¯”å“ªä¸€ä¸ªä¸€å®šå¥½, ä¸ç„¶å¦ä¸€ä¸ªæ—©å°±è¢«æ·˜æ±°äº†

ä¹‹ååœ¨ `__init__.py` å¯¹æ¥å¥½ `nonebot2` çš„ `api` å°±å¯ä»¥æ­£å¸¸ä½¿ç”¨äº†

### æ¥å…¥ ChatGLM

åœ¨æˆ‘ä»¬çš„ `agent.py` ä¸­æœ‰ä¸€ä¸ªç±»ä¸“é—¨ç®¡ç†å¤§æ¨¡å‹åç«¯, å« `LargeLanguageModelManager`

å®ƒå¯ä»¥è®©ä½ ç”¨ä¸Š `ChatGLM` ä¸“ç”¨çš„ `zhipuai` åº“, ç¨å¾®æ”¹ä¸€æ”¹å°±å¯ä»¥é€‚é…ä½ çš„äº†ï¼

```python
config = {
    'llm': {
        "llm-server": 'remote',
        "chatglm-api": "è¿™é‡Œæ”¾è¿›æ¥ä½ è‡ªå·±çš„ API Key",
        "prompt": r'E:\pandownload1\Projects\Nanoka-Nonebot2\nnk-bot\nnk_bot\plugins\nonebot_plugin_nanokabot_review\dataset\prompt.txt',
        "llama-path": r'E:\pandownload1\ML\Police\Project\models\DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf'
    }
}

# è¿™é‡Œé€‰æ‹©çš„æ˜¯ zhipuai, ä¹Ÿå°±æ˜¯åˆå§‹åŒ–çš„æ—¶å€™ä¸ä¼šåˆå§‹åŒ– Deepseek åç«¯, ä¸ä¼šå ç”¨èµ„æº
model = LargeLanguageModelManager(llm_model='zhipuai', config=config)

# å¦‚æœä½ æ˜¯åœ¨æƒ³ä¸å¼€æƒ³ç”¨æœ¬åœ°æœåŠ¡
model.change_llm_model(new_model='deepseek-r1') # ä»è¿™é‡Œå¼€å§‹åˆ›å»º DeepSeekServe æ ¸å¿ƒæœåŠ¡
```

ä½†ä½ è¿˜æ˜¯è¦åšä¸€äº›å°ä¿®æ”¹, æ¯”å¦‚è¯´æ¨¡å‹ğŸ‘‡

```python
class LargeLanguageModelManager():
    '''
    å¤§è¯­è¨€æ¨¡å‹æ¥å£ç±», ç”¨äºä¸è¯­è¨€æ¨¡å‹è¿›è¡Œäº¤äº’
    åŒæ—¶è´Ÿè´£ç®¡ç†è¯­è¨€æ¨¡å‹ç›¸å…³å†…å®¹
    '''

    # æ­¤å¤„çœç•¥å¥½å¤šæ–‡æœ¬

    def request_zhipuai_chatglm(self, content='') -> str:
        """
        è¯·æ±‚ ZhipuAI çš„ ChatGLM-4-Flash æ¨¡å‹è¿›è¡Œå¯¹è¯
        ç›´æ¥è¿”å›å•å¥è¯çš„å›å¤å†…å®¹, ä¸è¿›è¡Œä»»ä½•æ ¼å¼åŒ–å¤„ç†
        """
        if len(content) == 0:
            return False, "å†…å®¹ä¸èƒ½ä¸ºç©º"

        message = copy(self.prompt)
        message.append({"role": "user", "content": content})

        response = self.chatglm_model.chat.completions.create(
            model="glm-4-flash",   # ğŸ‘ˆ çœ‹è¿™é‡Œ, ä¸çœ‹è¿™é‡Œä½ ä¼šåƒè‹¦çš„
            messages=message,
        )

        return response.choices[0].message.content
```

### Bert è®­ç»ƒ

å¦‚æœä½ å‡†å¤‡å¥½äº†, é‚£ä¹ˆå°±å¼€å§‹è®­ç»ƒ `Bert` æ¨¡å‹äº†

```bash
# è¿›å…¥æ–‡ä»¶å¤¹
cd nnk_bot\plugins\nonebot_plugin_nanokabot_review
# å¼€å§‹è®­ç»ƒè¿‡ç¨‹
python bert.py
```

å…¶å®æ²¡å•¥éš¾çš„, ä¸»è¦è¿˜æ˜¯ä½ è¦è‡ªå·±å»æ‰¾è®­ç»ƒé›†, è€Œä¸”è®­ç»ƒ `Bert` çš„æ—¶å€™è¦å°½é‡ä¿è¯ $ lr \leq 10^{-5} $ è€Œä¸”æœ€åçš„ `classifier` å±‚æŒ‰ç…§ä½ çš„æ•°æ®ä¸ªæ•°è¿›è¡Œé€‚é…, ä¸€èˆ¬æ¥è¯´ $ lr \approx 10^{-3} $, èƒ½ç‚¼å‡ºå¥½ä¸¹çš„å‚æ•°å°±æ˜¯å¥½å‚æ•°å°±æ˜¯äº†...

è®­ç»ƒçš„ Bert æ¨¡å‹è¿˜æ˜¯å¯ä»¥çš„, æ”¶æ•›çš„æ¯”è¾ƒç¨³å®š, åªæ˜¯èƒ½ç¨³å®šåœ°è¾“å‡ºåƒåœ¾å¹¿å‘Šç±»å‹, å…¶ä»–çš„é»‘è¯å­¦ä¹ çš„æ•ˆæœä¸æ˜¯å¾ˆå¥½...å¦‚æœä½ çœŸçš„æƒ³è¦å»åšè¿™ä¸ªçš„è¯, æˆ‘å»ºè®®å…ˆæ”¶é›†ä¸€æ³¢ä½ ä»¬ç¾¤é‡Œå‘ç”Ÿçš„æ•°æ®, ç„¶åå†è¿›è¡Œè®­ç»ƒ

è®­ç»ƒæ—¥å¿—ä¸€èˆ¬åœ¨æ§åˆ¶å°ğŸ‘‡

```
BertForSequenceClassification LOAD REPORT from: bert-base-chinese
Key                                        | Status     |
-------------------------------------------+------------+-
cls.predictions.transform.LayerNorm.weight | UNEXPECTED |
cls.predictions.transform.dense.bias       | UNEXPECTED |
cls.seq_relationship.bias                  | UNEXPECTED |
cls.predictions.bias                       | UNEXPECTED |
cls.predictions.transform.dense.weight     | UNEXPECTED |
cls.seq_relationship.weight                | UNEXPECTED |
cls.predictions.transform.LayerNorm.bias   | UNEXPECTED |
classifier.bias                            | MISSING    |
classifier.weight                          | MISSING    |

Notes:
- UNEXPECTED    :can be ignored when loading from different task/architecture; not ok if you expect identical arch.
- MISSING       :those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.
æ•°æ®é›†ç»Ÿè®¡ï¼š label
0    219
1     40
Name: count, dtype: int64
Epoch 1/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 11.16it/s, loss=0.571]
Epoch 2/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 23.02it/s, loss=0.578]
Epoch 3/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 22.90it/s, loss=0.43]

... (å…± 54 æ¡æ•°æ®) ...

Epoch 57/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 22.50it/s, loss=0.24]
Epoch 58/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 22.69it/s, loss=0.199]
Epoch 59/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 22.77it/s, loss=0.214]
Epoch 60/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 22.68it/s, loss=0.21]
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 29.03it/s]
(Y) è¿›è¡Œæ¨¡å‹ä¿å­˜: models\classifier_only.pth
(N) æµ‹è¯•åå†ä¿å­˜
(y/N)

--------------------- äººå·¥æµ‹è¯•æ¨¡å¼ï¼ˆè¾“å…¥qé€€å‡ºï¼‰---------------------
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: ä½ è§‰å¾—å‘¢ï¼Ÿ
E:\pandownload1\Projects\Nanoka-Nonebot2\nnk-bot\nnk_bot\plugins\nonebot_plugin_nanokabot_review\bert.py:221: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  input_ids = torch.tensor(inputs['input_ids']).unsqueeze(0).to(device)
E:\pandownload1\Projects\Nanoka-Nonebot2\nnk-bot\nnk_bot\plugins\nonebot_plugin_nanokabot_review\bert.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  attention_mask = torch.tensor(inputs['attention_mask']).unsqueeze(0).to(device)
E:\pandownload1\Projects\Nanoka-Nonebot2\nnk-bot\nnk_bot\plugins\nonebot_plugin_nanokabot_review\bert.py:223: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  token_type_ids = torch.tensor(inputs['token_type_ids']).unsqueeze(0).to(device)
é¢„æµ‹ç»“æœ: 0
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: çœ‹èµ·æ¥è¿˜å‡‘åˆ
é¢„æµ‹ç»“æœ: 0
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: +++sdfsfsajfkhhbsdkj
é¢„æµ‹ç»“æœ: 0
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: iå•Šuiçš„è§„èŒƒå’Œç›‘æ§å’Œæ—¶ä»£æ­¥ä¼åŠ å¿«æ­¥ä¼å°±ç›‘æ§å’Œå˜å¯æ¥å—å¯¹æ–¹æ ¹æ®å®¢æˆ·
é¢„æµ‹ç»“æœ: 0
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: è‹¦äºåº”è¯¥æ˜¯çš„ç–¯ç‹‚è¿›æ”»å’Œè‘µèŠ±
é¢„æµ‹ç»“æœ: 0
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: parser.add_argument('--max_len', type=int, default=50, help='å¥å­æœ€å¤§é•¿åº¦')
é¢„æµ‹ç»“æœ: 0
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: æ·˜å®é—ªè´­â•åƒé—®å¤–å–åˆ¸åŒå åŠ ï¼ 1ï¸âƒ£æ·˜å®-é—ªè´­æœï¼š2892 å’Œ 13788 2ï¸âƒ£å»åƒé—®appä¸‹å•, å¯ä»¥åŒå åŠ  åƒé—®APPé¦–å•éšæœºç«‹å‡3.8~8.9äº“
é¢„æµ‹ç»“æœ: 1
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: ä½ è¿™ç“œå¤šå°‘é’±ä¸€æ–¤å•Š
é¢„æµ‹ç»“æœ: 0
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: ä¸¤å—é’±ä¸€æ–¤
é¢„æµ‹ç»“æœ: 0
è¾“å…¥è¦åˆ¤æ–­çš„å†…å®¹: q
åˆ†ç±»å¤´å‚æ•°å·²ä¿å­˜åˆ°: models\classifier_only.pth
```

